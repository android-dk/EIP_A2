{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SJyVpgSxHt4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "YlEUplvoxKAT",
    "outputId": "b99cf37e-e077-481f-fa06-788de7d535ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "I6Y9Va-xxMXG",
    "outputId": "d78eda39-e3a9-48cd-92f0-e149c3bc882c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5347083dd8>"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBoAg/EBThB4Ii/EBQhB8I6v8AG8x2aarNGp8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxDZxPhhxOgO"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HzMqbTnxQQW"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LdYiW6ixR9e"
   },
   "outputs": [],
   "source": [
    "y_train[:10]\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "rFR0F9j0xVp2",
    "outputId": "ce134a0b-5a39-416a-a6bd-dde0d6570de7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "colab_type": "code",
    "id": "o0WjZfoDdHkj",
    "outputId": "eba2a0a1-490b-4fdb-c48a-2c46ff9b7faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_254 (Conv2D)          (None, 26, 26, 4)         40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_198 (Bat (None, 26, 26, 4)         16        \n",
      "_________________________________________________________________\n",
      "dropout_198 (Dropout)        (None, 26, 26, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_255 (Conv2D)          (None, 24, 24, 8)         296       \n",
      "_________________________________________________________________\n",
      "batch_normalization_199 (Bat (None, 24, 24, 8)         32        \n",
      "_________________________________________________________________\n",
      "dropout_199 (Dropout)        (None, 24, 24, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_256 (Conv2D)          (None, 22, 22, 16)        1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_200 (Bat (None, 22, 22, 16)        64        \n",
      "_________________________________________________________________\n",
      "dropout_200 (Dropout)        (None, 22, 22, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_257 (Conv2D)          (None, 9, 9, 8)           1160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_201 (Bat (None, 9, 9, 8)           32        \n",
      "_________________________________________________________________\n",
      "dropout_201 (Dropout)        (None, 9, 9, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_258 (Conv2D)          (None, 7, 7, 16)          1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_202 (Bat (None, 7, 7, 16)          64        \n",
      "_________________________________________________________________\n",
      "dropout_202 (Dropout)        (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_259 (Conv2D)          (None, 5, 5, 32)          4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_203 (Bat (None, 5, 5, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_203 (Dropout)        (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_260 (Conv2D)          (None, 1, 1, 10)          330       \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 9,138\n",
      "Trainable params: 8,970\n",
      "Non-trainable params: 168\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(4, (3, 3), activation='relu', input_shape=(28,28,1))) # 26 x 26  x 4\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Convolution2D(8, (3, 3), activation='relu')) # 24x 24 x 8\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Convolution2D(16, (3, 3), activation='relu')) # 22x 22 x 16\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(MaxPooling2D(2,2)) # 11 x 11 x 16\n",
    "\n",
    "model.add(Convolution2D(8, (3, 3), activation='relu')) # 9 x 9 x 8\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Convolution2D(16, (3, 3), activation='relu')) # 7 x 7 x 16\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu')) # 5 x 5 x 32\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(AveragePooling2D(5,5)) # 1 x 1 x 32\n",
    "model.add(Convolution2D(10, (1,1), activation = 'relu')) # 1 x 1 x 10\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "L2IicGJ4x3Be",
    "outputId": "fdb7752f-77af-414a-cfd8-df2e3145dca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
      "60000/60000 [==============================] - 18s 292us/step - loss: 0.0382 - acc: 0.9875 - val_loss: 0.0369 - val_acc: 0.9897\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0325 - acc: 0.9893 - val_loss: 0.0313 - val_acc: 0.9910\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0293 - acc: 0.9904 - val_loss: 0.0250 - val_acc: 0.9920\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0281 - acc: 0.9915 - val_loss: 0.0217 - val_acc: 0.9934\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0253 - acc: 0.9921 - val_loss: 0.0202 - val_acc: 0.9935\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0227 - acc: 0.9927 - val_loss: 0.0196 - val_acc: 0.9933\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0229 - acc: 0.9928 - val_loss: 0.0207 - val_acc: 0.9936\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0222 - acc: 0.9926 - val_loss: 0.0192 - val_acc: 0.9942\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0212 - acc: 0.9931 - val_loss: 0.0182 - val_acc: 0.9940\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0199 - acc: 0.9935 - val_loss: 0.0211 - val_acc: 0.9940\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0194 - acc: 0.9938 - val_loss: 0.0210 - val_acc: 0.9936\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0201 - acc: 0.9935 - val_loss: 0.0204 - val_acc: 0.9932\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0193 - acc: 0.9935 - val_loss: 0.0186 - val_acc: 0.9947\n",
      "Epoch 14/20\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0189 - acc: 0.9941 - val_loss: 0.0182 - val_acc: 0.9945\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0192 - acc: 0.9939 - val_loss: 0.0185 - val_acc: 0.9947\n",
      "Epoch 16/20\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0179 - acc: 0.9943 - val_loss: 0.0191 - val_acc: 0.9942\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0178 - acc: 0.9944 - val_loss: 0.0185 - val_acc: 0.9942\n",
      "Epoch 18/20\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0178 - acc: 0.9947 - val_loss: 0.0183 - val_acc: 0.9945\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0167 - acc: 0.9948 - val_loss: 0.0181 - val_acc: 0.9948\n",
      "Epoch 20/20\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0168 - acc: 0.9946 - val_loss: 0.0187 - val_acc: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8d84c2f98>"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(lambda epoch: round(0.003 * 1/(1 + 0.319 * epoch), 10), verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WLxlW9ufyQiO",
    "outputId": "b03f12ae-b81b-4d2d-e0f0-546e9b9c53c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.018715105919671623, 0.994]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2qDl21ozBnW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EIGHTH.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
